{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Parimala-15/ShadowFox/blob/main/Task1/Image_Classifier.ipynb","timestamp":1761742889933}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kryQQJwq0e4t","outputId":"98cf204d-0464-4ddc-8f2b-909e08606cf6","executionInfo":{"status":"ok","timestamp":1761743114581,"user_tz":-330,"elapsed":4896,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}],"source":["!pip install torch torchvision torchsummary numpy matplotlib"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n","import matplotlib.pyplot as plt\n","import numpy as np"],"metadata":{"id":"iFzQ95Hs1Wtg","executionInfo":{"status":"ok","timestamp":1761743109682,"user_tz":-330,"elapsed":10498,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# Check device availability\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"✅ Using GPU: CUDA\")\n","elif torch.backends.mps.is_available():\n","    device = torch.device(\"mps\")  # For Macbooks with Apple Silicon\n","    print(\"✅ Using GPU: Apple MPS\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"⚠️ Using CPU (slowest).\")\n","\n","# Optional: Double check\n","print(f\"Using device: {device}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrvnuoJc1cJH","outputId":"05f8c329-dfc4-4ddf-84b6-03094f094277","executionInfo":{"status":"ok","timestamp":1761743114660,"user_tz":-330,"elapsed":7,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Using GPU: CUDA\n","Using device: cuda\n"]}]},{"cell_type":"code","source":["# Training: Add augmentation\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Validation/Test: Only normalize\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n"],"metadata":{"id":"WTc_66af2FHf","executionInfo":{"status":"ok","timestamp":1761743114664,"user_tz":-330,"elapsed":2,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Re-create original dataset with `transform=None` so we can apply it manually to subsets\n","base_train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n","\n","# Split the raw dataset\n","train_size = int(0.8 * len(base_train_set))\n","val_size = len(base_train_set) - train_size\n","train_dataset_raw, val_dataset_raw = torch.utils.data.random_split(base_train_set, [train_size, val_size])\n","\n","# Manually apply transforms using transforms property\n","train_dataset_raw.dataset.transform = train_transform\n","val_dataset_raw.dataset.transform = test_transform\n","\n","# Create loaders\n","train_loader = torch.utils.data.DataLoader(train_dataset_raw, batch_size=4, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset_raw, batch_size=4, shuffle=False)\n","\n","# Test set with test_transform\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False)"],"metadata":{"id":"4o6RmFsy8eiO","executionInfo":{"status":"ok","timestamp":1761743149877,"user_tz":-330,"elapsed":1493,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print('Number of images in the training dataset:', len(train_dataset_raw))\n","print('Number of images in the testing dataset:', len(test_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbhNpbvX2IoO","outputId":"85f356bc-4605-4cbb-f671-f210b03e8b31","executionInfo":{"status":"ok","timestamp":1761743183925,"user_tz":-330,"elapsed":9,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in the training dataset: 40000\n","Number of images in the testing dataset: 10000\n"]}]},{"cell_type":"code","source":["print(f\"Shape of the images in the training dataset: {train_loader.dataset[0][0].shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FlKmWN_2WI_","outputId":"9d131fdd-1f1c-461b-b0ea-55e9eb7b90a7","executionInfo":{"status":"ok","timestamp":1761743186572,"user_tz":-330,"elapsed":17,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the images in the training dataset: torch.Size([3, 32, 32])\n"]}]},{"cell_type":"code","source":["\n","fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n","for i in range(10):\n","    image = train_loader.dataset[i][0].permute(1, 2, 0)\n","    denormalized_image= image / 2 + 0.5\n","    axes[i].imshow(denormalized_image)\n","    axes[i].set_title(classes[train_loader.dataset[i][1]])\n","    axes[i].axis('off')\n","plt.show()"],"metadata":{"id":"N_VC0Qn02YxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fc2bdc9","executionInfo":{"status":"ok","timestamp":1761743211333,"user_tz":-330,"elapsed":15,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"source":["classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\n","class ConvNeuralNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),      # (3,32,32) → (64,32,32)\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),                              # → (64,16,16)\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),    # → (128,16,16)\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),                              # → (128,8,8)\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),   # → (256,8,8)\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),                              # → (256,4,4)\n","\n","            nn.Dropout(0.3)\n","        )\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))          # → (256,1,1)\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 10),\n","            nn.LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","\n","net = ConvNeuralNet()\n","net.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M18sz93U2d8H","outputId":"fed99512-94a8-405c-af69-e2b0711841c8","executionInfo":{"status":"ok","timestamp":1761743225530,"user_tz":-330,"elapsed":197,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNeuralNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU()\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Dropout(p=0.3, inplace=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=256, out_features=128, bias=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.3, inplace=False)\n","    (4): Linear(in_features=128, out_features=10, bias=True)\n","    (5): LogSoftmax(dim=1)\n","  )\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["summary(net, (3, 32, 32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1WbvKn22hMe","outputId":"92d57ed4-3063-4cd2-c925-46f8a20a1ffe","executionInfo":{"status":"ok","timestamp":1761743234640,"user_tz":-330,"elapsed":872,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","         MaxPool2d-4           [-1, 64, 16, 16]               0\n","            Conv2d-5          [-1, 128, 16, 16]          73,856\n","       BatchNorm2d-6          [-1, 128, 16, 16]             256\n","              ReLU-7          [-1, 128, 16, 16]               0\n","         MaxPool2d-8            [-1, 128, 8, 8]               0\n","            Conv2d-9            [-1, 256, 8, 8]         295,168\n","      BatchNorm2d-10            [-1, 256, 8, 8]             512\n","             ReLU-11            [-1, 256, 8, 8]               0\n","        MaxPool2d-12            [-1, 256, 4, 4]               0\n","          Dropout-13            [-1, 256, 4, 4]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 1, 1]               0\n","          Flatten-15                  [-1, 256]               0\n","           Linear-16                  [-1, 128]          32,896\n","             ReLU-17                  [-1, 128]               0\n","          Dropout-18                  [-1, 128]               0\n","           Linear-19                   [-1, 10]           1,290\n","       LogSoftmax-20                   [-1, 10]               0\n","================================================================\n","Total params: 405,898\n","Trainable params: 405,898\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 2.88\n","Params size (MB): 1.55\n","Estimated Total Size (MB): 4.44\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["\n","loss_function = nn.NLLLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","epochs = 10\n","for epoch in range(epochs):\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader):\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = loss_function(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:\n","            print(f'[{epoch + 1}/{epochs}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abcPAZk92jfu","outputId":"0e189dab-992d-43f0-8875-597fbf10f1e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1/10,  2000] loss: 1.982\n","[1/10,  4000] loss: 1.834\n","[1/10,  6000] loss: 1.735\n","[1/10,  8000] loss: 1.643\n","[1/10, 10000] loss: 1.583\n","[2/10,  2000] loss: 1.515\n","[2/10,  4000] loss: 1.511\n","[2/10,  6000] loss: 1.441\n","[2/10,  8000] loss: 1.404\n","[2/10, 10000] loss: 1.390\n","[3/10,  2000] loss: 1.335\n","[3/10,  4000] loss: 1.316\n","[3/10,  6000] loss: 1.291\n","[3/10,  8000] loss: 1.263\n","[3/10, 10000] loss: 1.240\n","[4/10,  2000] loss: 1.190\n","[4/10,  4000] loss: 1.167\n","[4/10,  6000] loss: 1.181\n","[4/10,  8000] loss: 1.184\n","[4/10, 10000] loss: 1.127\n","[5/10,  2000] loss: 1.074\n","[5/10,  4000] loss: 1.077\n","[5/10,  6000] loss: 1.071\n","[5/10,  8000] loss: 1.054\n","[5/10, 10000] loss: 1.033\n","[6/10,  2000] loss: 0.992\n","[6/10,  4000] loss: 0.988\n","[6/10,  6000] loss: 0.986\n","[6/10,  8000] loss: 0.968\n","[6/10, 10000] loss: 0.985\n","[7/10,  2000] loss: 0.892\n","[7/10,  4000] loss: 0.929\n","[7/10,  6000] loss: 0.907\n","[7/10,  8000] loss: 0.916\n","[7/10, 10000] loss: 0.917\n","[8/10,  2000] loss: 0.850\n","[8/10,  4000] loss: 0.862\n","[8/10,  6000] loss: 0.838\n","[8/10,  8000] loss: 0.839\n","[8/10, 10000] loss: 0.824\n","[9/10,  2000] loss: 0.786\n","[9/10,  4000] loss: 0.782\n","[9/10,  6000] loss: 0.789\n","[9/10,  8000] loss: 0.795\n"]}]},{"cell_type":"code","source":["def view_classification(image, probabilities):\n","    probabilities = probabilities.data.numpy().squeeze()\n","\n","    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n","\n","    image = image.permute(1, 2, 0)\n","    denormalized_image= image / 2 + 0.5\n","    ax1.imshow(denormalized_image)\n","    ax1.axis('off')\n","    ax2.barh(np.arange(10), probabilities)\n","    ax2.set_aspect(0.1)\n","    ax2.set_yticks(np.arange(10))\n","    ax2.set_yticklabels(classes)\n","    ax2.set_title('Class Probability')\n","    ax2.set_xlim(0, 1.1)\n","    plt.tight_layout()"],"metadata":{"id":"LImg-BVF5KiX","executionInfo":{"status":"aborted","timestamp":1761743124934,"user_tz":-330,"elapsed":18206,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","images, _ = next(iter(test_loader))\n","\n","image = images[2]\n","batched_image = image.unsqueeze(0).to(device)\n","with torch.no_grad():\n","    log_probabilities = net(batched_image)\n","\n","probabilities = torch.exp(log_probabilities).squeeze().cpu()\n","view_classification(image, probabilities)"],"metadata":{"id":"tdDBQmXs5NOH","executionInfo":{"status":"aborted","timestamp":1761743124935,"user_tz":-330,"elapsed":18204,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n"],"metadata":{"id":"NqZOr58t7pY-","executionInfo":{"status":"aborted","timestamp":1761743125077,"user_tz":-330,"elapsed":6,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_true = []\n","y_pred = []\n","\n","net.eval()  # Set to eval mode\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs, 1)\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n"],"metadata":{"id":"-Z9BBaGr7r5v","executionInfo":{"status":"aborted","timestamp":1761743125079,"user_tz":-330,"elapsed":7,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n📊 Classification Report:\\n\")\n","print(classification_report(y_true, y_pred, target_names=classes))\n"],"metadata":{"id":"ls8QXtov7uG_","executionInfo":{"status":"aborted","timestamp":1761743125081,"user_tz":-330,"elapsed":9,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=classes, yticklabels=classes)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title(' Confusion Matrix')\n","plt.show()\n"],"metadata":{"id":"H9TpiFaZ7wlG","executionInfo":{"status":"aborted","timestamp":1761743125082,"user_tz":-330,"elapsed":9,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","\n","# Define split sizes\n","train_size = int(0.8 * len(train_set))   # 80% for training\n","val_size = len(train_set) - train_size   # 20% for validation\n","\n","# Create splits\n","train_dataset, val_dataset = random_split(train_set, [train_size, val_size])\n"],"metadata":{"id":"aI-0lD7X8GDX","executionInfo":{"status":"aborted","timestamp":1761743125083,"user_tz":-330,"elapsed":8,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False)\n"],"metadata":{"id":"HB_L7ljm8H9n","executionInfo":{"status":"aborted","timestamp":1761743125084,"user_tz":-330,"elapsed":7,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# After training loop per epoch\n","val_loss = 0.0\n","net.eval()  # evaluation mode disables dropout, etc.\n","with torch.no_grad():\n","    for val_inputs, val_labels in val_loader:\n","        val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n","        val_outputs = net(val_inputs)\n","        val_loss += loss_function(val_outputs, val_labels).item()\n","\n","avg_val_loss = val_loss / len(val_loader)\n","print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss:.4f}\")\n","net.train()  # switch back to training mode\n"],"metadata":{"id":"NxGPshGt8Kl_","executionInfo":{"status":"aborted","timestamp":1761743125085,"user_tz":-330,"elapsed":18340,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save model state dict\n","torch.save(net.state_dict(), 'cnn_cifar10.pth')\n","print(\"🧠 Model saved as 'cnn_cifar10.pth'\")\n"],"metadata":{"id":"hnGomnzZ83OX","executionInfo":{"status":"aborted","timestamp":1761743125086,"user_tz":-330,"elapsed":18338,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load model\n","loaded_model = ConvNeuralNet()\n","loaded_model.load_state_dict(torch.load('cnn_cifar10.pth', map_location=device))\n","loaded_model.to(device)\n","loaded_model.eval()\n"],"metadata":{"id":"nvJHaCo185BH","executionInfo":{"status":"aborted","timestamp":1761743125087,"user_tz":-330,"elapsed":18336,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","\n","def predict_image(image_path, model, transform, class_names):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image = transform(image).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        output = model(image)\n","        probs = torch.exp(output)\n","        top_p, top_class = probs.topk(1, dim=1)\n","\n","    predicted_class = class_names[top_class.item()]\n","    confidence = top_p.item()\n","    return predicted_class, confidence\n"],"metadata":{"id":"_vRrdoIG861A","executionInfo":{"status":"aborted","timestamp":1761743125088,"user_tz":-330,"elapsed":18337,"user":{"displayName":"Harish.P.G","userId":"00501176519175796277"}}},"execution_count":null,"outputs":[]}]}